{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b8c3b7-fc95-43d8-8b5a-dc5ad56809b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def display(img,cmap='gray'):\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img,cmap='gray')\n",
    "\n",
    "def get_black_contour(image):\n",
    "    \n",
    "    sep_blur = cv2.medianBlur(image,305)\n",
    "\n",
    "    gray_sep_coins = cv2.cvtColor(sep_blur, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, sep_thresh = cv2.threshold(gray_sep_coins,100,220,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    contours,hierarchy = cv2.findContours(sep_thresh.copy(),cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contour_list = []\n",
    "    for contour in contours:\n",
    "        approx = cv2.approxPolyDP(contour,0.01*cv2.arcLength(contour,True),True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        if ((len(approx) > 10) & (area > 3000) ):\n",
    "            contour_list.append(contour)\n",
    "\n",
    "    if len(contour_list) == 2:\n",
    "        area1 = cv2.contourArea(contour_list[0])\n",
    "        area2 = cv2.contourArea(contour_list[1])\n",
    "        if area1 > area2:\n",
    "            contour_list.pop(1)\n",
    "        else:\n",
    "            contour_list.pop(0)\n",
    "        \n",
    "    return contour_list[0]\n",
    "\n",
    "\n",
    "def scale_contour(cnt, scale):\n",
    "    M = cv2.moments(cnt)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "\n",
    "    cnt_norm = cnt - [cx, cy]\n",
    "    cnt_scaled = cnt_norm * scale\n",
    "    cnt_scaled = cnt_scaled + [cx, cy]\n",
    "    cnt_scaled = cnt_scaled.astype(np.int32)\n",
    "\n",
    "    return cnt_scaled\n",
    "\n",
    "\n",
    "def crop_image(image):\n",
    "    \n",
    "    black_contour = get_black_contour(image)\n",
    "\n",
    "    double_contour = scale_contour(black_contour, 3.5)\n",
    "\n",
    "\n",
    "    x,y,w,h = cv2.boundingRect(double_contour)\n",
    "    image.shape[0]\n",
    "\n",
    "\n",
    "    if x < 0:\n",
    "        x = 0\n",
    "\n",
    "    if y < 0:\n",
    "        y = 0\n",
    "\n",
    "\n",
    "    img = image.copy()\n",
    "    # Crop the image using the bounding box\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "\n",
    "    return x,y,w,h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994c7499-fddd-46a8-bd8c-f77938dc09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import os\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "def overlay_transparent(background, overlay, x, y):\n",
    "\n",
    "    background_width = background.shape[1]\n",
    "    background_height = background.shape[0]\n",
    "\n",
    "    if x >= background_width or y >= background_height:\n",
    "        return background\n",
    "\n",
    "    h, w = overlay.shape[0], overlay.shape[1]\n",
    "\n",
    "    if x + w > background_width:\n",
    "        w = background_width - x\n",
    "        overlay = overlay[:, :w]\n",
    "\n",
    "    if y + h > background_height:\n",
    "        h = background_height - y\n",
    "        overlay = overlay[:h]\n",
    "\n",
    "    if overlay.shape[2] < 4:\n",
    "        overlay = np.concatenate(\n",
    "            [\n",
    "                overlay,\n",
    "                np.ones((overlay.shape[0], overlay.shape[1], 1), dtype = overlay.dtype) * 255\n",
    "            ],\n",
    "            axis = 2,\n",
    "        )\n",
    "\n",
    "    overlay_image = overlay[..., :3]\n",
    "    mask = overlay[..., 3:] / 255.0\n",
    "\n",
    "    background[y:y+h, x:x+w] = (1.0 - mask) * background[y:y+h, x:x+w] + mask * overlay_image\n",
    "\n",
    "    return background\n",
    "\n",
    "def decide_shot_img(aspect, black_dot, points, directory_size_white, directory_size_black, directory_size_blackwhite):\n",
    "    \n",
    "    #standard white shot\n",
    "    random_shot = random.randint(1, directory_size_white)\n",
    "    shot = cv2.imread(f'shootanalysisdataset/schotennobg/shotwhite/{random_shot}.png', cv2.IMREAD_UNCHANGED)\n",
    "    shot = ndimage.rotate(shot, random.randint(1, 360))\n",
    "\n",
    "    #startpoint is in black contour select different shot\n",
    "    for point in points:\n",
    "        if cv2.pointPolygonTest(black_dot, (point[0],point[1]), False) > 0:\n",
    "            point[2] = True        \n",
    "\n",
    "    true_count = 0\n",
    "    for inner_array in points:\n",
    "        if inner_array[2] == True:\n",
    "            true_count += 1\n",
    "    \n",
    "    #if count > 2 means that 3 or more corner points are in the black contour. Black shot is selected\n",
    "    if true_count > 2:\n",
    "        random_shot = random.randint(1, directory_size_black)\n",
    "        shot = cv2.imread(f'shootanalysisdataset/schotennobg/shotblack/{random_shot}.png', cv2.IMREAD_UNCHANGED)\n",
    "        shot = ndimage.rotate(shot, random.randint(1, 360))\n",
    "\n",
    "    elif true_count == 2:\n",
    "        shot = cv2.imread(f'shootanalysisdataset/schotennobg/shotblackwhite/1.png', cv2.IMREAD_UNCHANGED)\n",
    "        if points[3][2] and points[0][2]:\n",
    "            shot = ndimage.rotate(shot, 300)\n",
    "        elif points[0][2] and points[1][2]:\n",
    "\n",
    "            shot = ndimage.rotate(shot, 30)\n",
    "        elif points[1][2] and points[2][2]:\n",
    "\n",
    "            shot = ndimage.rotate(shot, 120)\n",
    "        elif points[2][2] and points[3][2]:\n",
    "            shot = ndimage.rotate(shot, 45)\n",
    "\n",
    "                \n",
    "    \n",
    "    shot = cv2.resize(shot, (int(shot.shape[1] * aspect), int(shot.shape[0])))\n",
    "    \n",
    "    return shot\n",
    "\n",
    "def create_xml(max_width, max_height, filename):\n",
    "    f = open(f\"shootanalysisdataset/annotations/{filename}_annotation.xml\", \"w+\")\n",
    "    f.write(f\"<folder></folder><filename>{filename}</filename><path>{filename}</path><source><database>roboflow.ai</database></source>\")\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "def generate_shots(amount, image, black_dot, aspect,x,y,w,h,filename):\n",
    "    \n",
    "    dir_path_white = r'C:\\projects\\python-cv\\shootanalysisdataset\\schotennobg\\shotwhite'\n",
    "    dir_path_black = r'C:\\projects\\python-cv\\shootanalysisdataset\\schotennobg\\shotblack'\n",
    "    dir_path_blackwhite = r'C:\\projects\\python-cv\\shootanalysisdataset\\schotennobg\\shotblackwhite'\n",
    "    \n",
    "    directory_size_white = len([entry for entry in os.listdir(dir_path_white) if os.path.isfile(os.path.join(dir_path_white, entry))])\n",
    "    directory_size_black = len([entry for entry in os.listdir(dir_path_black) if os.path.isfile(os.path.join(dir_path_black, entry))])\n",
    "    directory_size_blackwhite = len([entry for entry in os.listdir(dir_path_blackwhite) if os.path.isfile(os.path.join(dir_path_blackwhite, entry))])\n",
    "    \n",
    "    background = image.copy()\n",
    "    counter_pounter = 0\n",
    "    \n",
    "    while counter_pounter < amount:\n",
    "            \n",
    "        max_width = image.shape[1]\n",
    "        max_height = image.shape[0]\n",
    "        \n",
    "        \n",
    "        startpoint_x = random.randint(x, w)\n",
    "        startpoint_y = random.randint(y, w)\n",
    "        endpoint_x = startpoint_x + 180\n",
    "        endpoint_y = startpoint_y + 160\n",
    "        \n",
    "        points = [[startpoint_x, startpoint_y, False],\n",
    "                  [endpoint_x, startpoint_y, False],\n",
    "                  [endpoint_x, endpoint_y, False],\n",
    "                  [startpoint_x, endpoint_y, False]]\n",
    "        \n",
    "        shot_img_proposed = decide_shot_img(aspect, black_dot, points, directory_size_white, directory_size_black, directory_size_blackwhite)\n",
    "                \n",
    "        background = overlay_transparent(background, shot_img_proposed, startpoint_x, startpoint_y)\n",
    "        #cv2.drawContours(background, [black_dot],  -1, (255,0,0), 2)\n",
    "\n",
    "        counter_pounter += 1\n",
    "    \n",
    "    create_xml(max_width, max_height, filename)\n",
    "    \n",
    "    \n",
    "    return background\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be026914-e1dd-4a35-98c4-0ec35b5a8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import _thread\n",
    "import time\n",
    "\n",
    "def generate_image_versions(i,photo):\n",
    "    sep_coins = cv2.imread(f'shootanalysisdataset/imagesnoshots/{photo}')\n",
    "    #sep_coins = cv2.imread(f'shootanalysisdataset/clean_target_1.jpeg')\n",
    "\n",
    "    x,y,w,h = crop_image(sep_coins)\n",
    "    black_dot = get_black_contour(sep_coins)\n",
    "    aspect = w / h\n",
    "    \n",
    "    print(black_dot.shape)\n",
    "    \n",
    "    for x in range(1):\n",
    "        background = generate_shots(5, sep_coins, black_dot, aspect,x,y,w,h,photo)\n",
    "        filename = f\"{i + 1}_v{(x + 1)}\"\n",
    "        cv2.imwrite(f'shootanalysisdataset/generatedcleantargetdataset/{filename}.jpg', background)\n",
    "        \n",
    "def generate_images():\n",
    "    #dir_path_standard_dataset = r'C:\\projects\\python-cv\\shootanalysisdataset\\dataset'\n",
    "    \n",
    "    #directory_size_white = len([entry for entry in os.listdir(dir_path_standard_dataset) if os.path.isfile(os.path.join(dir_path_standard_dataset, entry))])\n",
    "\n",
    "    directory_content = os.listdir(f'shootanalysisdataset/imagesnoshots')\n",
    "    \n",
    "    \n",
    "    # Create two threads as follows\n",
    "    for i, photo in enumerate(directory_content):\n",
    "       _thread.start_new_thread(generate_image_versions, (i,photo,) )\n",
    "    \n",
    "\n",
    "generate_images()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8fccfaf-ff3b-4038-95a0-7be1d9980532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True, 'id': 'DnGx7pwFTq58rG9hCDPX'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# Load Image with PIL\n",
    "image = Image.open(\"shootanalysisdataset/imagesnoshots/20230327_171231.jpg\").convert(\"RGB\")\n",
    "\n",
    "# Convert to JPEG Buffer\n",
    "buffered = io.BytesIO()\n",
    "image.save(buffered, quality=90, format=\"JPEG\")\n",
    "\n",
    "# Base 64 Encode\n",
    "img_str = base64.b64encode(buffered.getvalue())\n",
    "img_str = img_str.decode(\"ascii\")\n",
    "\n",
    "# Construct the URL\n",
    "upload_url = \"\".join([\n",
    "    \"https://api.roboflow.com/dataset/project-oqaxk/upload\",\n",
    "    \"?api_key=2VxY5QSMcnVFkUsgrxjV\",\n",
    "    \"&name=shootanalysisdataset/imagesnoshots/20230327_171228.jpg\",\n",
    "    \"&split=train\"\n",
    "])\n",
    "\n",
    "# POST to the API\n",
    "r = requests.post(upload_url, data=img_str, headers={\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "})\n",
    "\n",
    "# Output result\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9d536-ad3d-4b06-946a-9de8b3a40f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
